{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESCARGA Y CÁLCULO DEL SENTIMIENTO DE NOTICIAS DEL DIARIO PORTAFOLIO\n",
    "\n",
    "Este notebook describe el paso a paso que permitirá calcular el sentimiento de las noticias publicadas en el diario [Portafolio](https://www.portafolio.co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Instalación de software necesario\n",
    "\n",
    "--- Python\n",
    "\n",
    "Puede obtenerse instalando [Anaconda](https://www.anaconda.com). Para ello, ingrese [aquí](https://www.anaconda.com/products/distribution), descargue el instalador y ejecútelo.\n",
    "\n",
    "--- Git\n",
    "\n",
    "Ingrese [aquí](https://git-scm.com/downloads), descargue el instalador y ejecútelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Instalación de dependencias\n",
    "\n",
    "Para ello, ejecute la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scrapy==2.6.1\n",
    "!pip install pyodbc==4.0.32\n",
    "!pip install nltk==3.6.5\n",
    "!pip install textblob==0.17.1\n",
    "!pip install transformers==4.17.0\n",
    "!pip install pysftp==0.2.9\n",
    "!pip install ipywidgets==7.6.5\n",
    "!pip install deep-translator==1.8.3\n",
    "!pip install sentiment-analysis-spanish==0.0.25\n",
    "!pip install pysentimiento==0.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2.1: Carga de librerías necesarias\n",
    "\n",
    "Para ello, ejecute la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIBRERÍAS IMPORTADAS CORRECTAMENTE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from toolbox import get_date_inputs, clean_news, translate_news, upload_to_lz, save_local\n",
    "\n",
    "from pysentimiento import create_analyzer\n",
    "from sentiment_analysis_spanish import sentiment_analysis\n",
    "import nltk\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "\n",
    "nltk.download([\n",
    "  \"names\",\n",
    "  \"stopwords\",\n",
    "  \"state_union\",\n",
    "  \"twitter_samples\",\n",
    "  \"movie_reviews\",\n",
    "  \"averaged_perceptron_tagger\",\n",
    "  \"vader_lexicon\",\n",
    "  \"punkt\",\n",
    "])\n",
    "\n",
    "clear_output(wait = True)\n",
    "\n",
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "sentiment = sentiment_analysis.SentimentAnalysisSpanish()\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone', num_labels = 3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "nlp = pipeline(\"sentiment-analysis\", model = finbert, tokenizer = tokenizer)\n",
    "\n",
    "clear_output(wait = False)\n",
    "print('LIBRERÍAS IMPORTADAS CORRECTAMENTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Descarga de la última versión del código fuente (código que permitirá la descarga de las noticias)\n",
    "\n",
    "Para ello, es necesario ejecutar la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!if exist portafolio_news_scraper (rmdir /s /q portafolio_news_scraper)\n",
    "\n",
    "REPOSITORY_URL = 'http://sbmdeqpc04/data-extraction-dasolano/portafolio_news_scraper'\n",
    "\n",
    "!git clone $REPOSITORY_URL\n",
    "clear_output(wait = True)\n",
    "\n",
    "!if exist portafolio_news_scraper (echo 'LA ULTIMA VERSION DEL CODIGO FUE DESCARGADA EXITOSAMENTE') else (echo '¡ERROR!: EL CODIGO NO PUDO SER DESCARGADO. REVISE CONEXION Y VPN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Descarga de las noticias de interés\n",
    "\n",
    "Las noticias se pueden filtrar por:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Términos de busqueda*  \n",
    "\n",
    "Inmediatamente después de la siguiente celda usted tendrá la oportunidad de ingresar los términos sobre los cuales quiere buscar noticias. Cada vez que le aparezca\n",
    "un campo para ingresar texto escriba el término de interés y presione la tecla *enter*. Por favor no escriba palabras que no agregan significado; por ejemplo, en vez de escribir \"Banco de la República\" escriba \"Banco República\", o en vez de \"Grupo de Energía de Bogotá\" escriba \"Grupo Energía Bogotá\". Si ya escribió todos los términos de interés, en vez de escribir uno adicional presione la tecla *enter*.\n",
    "En caso de que quiera buscar todas las noticias (es decir, todas y absolutamente todas las que el programa encuentre), simplemente presione la tecla *enter* cuando le aparezca por primera vez el campo de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Términos de búsqueda: ['BANCOLOMBIA', 'DAVIVIENDA']\n"
     ]
    }
   ],
   "source": [
    "SEARCH_TERMS = []\n",
    "\n",
    "while True:\n",
    "  search_term = input('Ingrese el término de búsqueda o presione la tecla ENTER para terminar\\n').strip().upper()\n",
    "  if not search_term:\n",
    "    break\n",
    "  SEARCH_TERMS.append(search_term)\n",
    "\n",
    "print('Términos de búsqueda:', SEARCH_TERMS if SEARCH_TERMS else 'TODAS LAS NOTICIAS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Fechas inicial y final*\n",
    "\n",
    "De la misma manera, inmediatamente después de siguiente celda debe indicar el periodo en el que se quieren buscar noticias. Para ello, ingrese el mes (por ejemplo: \"Febrero\") y el año (por ejemplo: 2021) inicial y el mes y el año final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      " FECHA INICIAL\n",
      "****************************************\n",
      "****************************************\n",
      "FECHA FINAL\n",
      "****************************************\n",
      "****************************************\n",
      "\n",
      "Fecha inicial: Diciembre de 2021\n",
      "Fecha final: Enero de 2022\n"
     ]
    }
   ],
   "source": [
    "start_month, start_year, end_month, end_year = get_date_inputs()\n",
    "START_DATE = f'{start_year}-{start_month}'\n",
    "END_DATE = f'{end_year}-{end_month}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NOTICIAS DESCARGADAS CON EXITO'\n"
     ]
    }
   ],
   "source": [
    "!if exist news (rmdir /s /q news)\n",
    "SEARCH_TERMS_STR = ','.join(SEARCH_TERMS)\n",
    "current_year = int(start_year)\n",
    "end_year = int(end_year)\n",
    "\n",
    "while current_year <= end_year:\n",
    "  current_start_date = f'{current_year}-{start_month if current_year == int(start_year) else \"01\"}'\n",
    "  current_end_date = f'{current_year}-{12 if current_year < end_year else end_month}'\n",
    "  !cd portafolio_news_scraper && scrapy crawl news -a search_terms=\"$SEARCH_TERMS_STR\" -a start_date=$current_start_date -a end_date=$current_end_date -o ..\\news\\news-\"$current_year\".csv\n",
    "  clear_output(wait = True)\n",
    "  current_year += 1\n",
    "\n",
    "clear_output(wait = False)\n",
    "!if exist news (echo 'NOTICIAS DESCARGADAS CON EXITO') else (echo '¡ERROR!: ALGO OCURRIO, INTENTE NUEVAMENTE ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Limpieza de texto y filtrado de las noticias\n",
    "\n",
    "Las noticias obtenidas tienen algunos caracteres y textos no deseados. Adicionalmente, algunos resultados están duplicados, así como otros que no coinciden con el término de busqueda empleado en ésta. Para limpiar el texto y filtrar las noticias, ejecute la celda inferior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTICIAS DEL AÑO 2021 FUERON LIMPIADAS Y FILTRADAS\n",
      "NOTICIAS DEL AÑO 2022 FUERON LIMPIADAS Y FILTRADAS\n",
      "**************************************************\n",
      "LIMPIEZA Y FILTRADO CONCLUYERON EXITOSAMENTE\n"
     ]
    }
   ],
   "source": [
    "for current_year in range(int(start_year), int(end_year) + 1):\n",
    "  current_news = pd.read_csv(f'news/news-{current_year}.csv')\n",
    "  current_news = current_news.astype(str)\n",
    "  \n",
    "  news_cleaned = clean_news(current_news)\n",
    "  !del news\\news-\"$current_year\".csv\n",
    "  news_cleaned.to_csv(f'news/news-{current_year}.csv', index = False)\n",
    "  print(f'NOTICIAS DEL AÑO {current_year} FUERON LIMPIADAS Y FILTRADAS')\n",
    "\n",
    "print('*' * 50)\n",
    "print('LIMPIEZA Y FILTRADO CONCLUYERON EXITOSAMENTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5.1 (OPCIONAL): Persistencia de las noticias (destino: local)\n",
    "Las noticias serán guardadas en el mismo directorio de este notebook como **ALL_NEWS.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAS NOTICIAS FUERON GUARDADAS EXITOSAMENTE COMO ALL_NEWS.csv\n"
     ]
    }
   ],
   "source": [
    "save_local('news', 'ALL_NEWS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5.2 (OPCIONAL): Persistencia de las noticias (destino: nube)\n",
    "En caso de querer subir información a la nube se debe utilizar el método **upload_to_lz()**, en donde *database* es el nombre de la base de datos a la cual usted esté autorizado y *table_name* el nombre con el que la tabla quedará cargada en la nube. Tenga en cuenta que en el mismo directorio de este notebook debe existir un archivo llamado **credentials.json**, debe contener lo siguiente: **{ \"user\": \"su_usuario\", \"password\": \"su_contraseña\", \"server\": \"sbmdeblze004\" }**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAS NOTICIAS HAN SIDO CARGADAS A LA NUBE EXITOSAMENTE. UBICACIÓN LZ: proceso.dasolano_portafolio_news\n"
     ]
    }
   ],
   "source": [
    "save_local('news', 'ALL_NEWS')\n",
    "all_news = pd.read_csv('ALL_NEWS.csv')\n",
    "all_news = all_news.astype(str)\n",
    "\n",
    "database = 'proceso'\n",
    "table_name = 'dasolano_portafolio_news'\n",
    "\n",
    "upload_to_lz(dataframe = all_news, database = database, table_name = table_name)\n",
    "clear_output(wait = True)\n",
    "!del ALL_NEWS.csv\n",
    "print(f'LAS NOTICIAS HAN SIDO CARGADAS A LA NUBE EXITOSAMENTE. UBICACIÓN LZ: {database}.{table_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6: Cálculo del sentimiento en español (título, subtítulo y contenido)\n",
    "\n",
    "Se calcula el sentimiento del título, subtitulo y contenido de cada noticia usando las librerías [pysentimiento](https://github.com/pysentimiento/pysentimiento)\n",
    "y [sentiment-spanish](https://github.com/sentiment-analysis-spanish/sentiment-spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('news_sentiment_spanish'):\n",
    "  if os.listdir('news_sentiment_spanish'):\n",
    "    !rmdir /s /q news_sentiment_spanish\n",
    "    !mkdir news_sentiment_spanish\n",
    "else:\n",
    "  !mkdir news_sentiment_spanish\n",
    "\n",
    "for current_year in range(int(start_year), int(end_year) + 1):\n",
    "\n",
    "  news_spanish = pd.read_csv(f'news/news-{current_year}.csv')\n",
    "  news_spanish = news_spanish.astype(str)\n",
    "\n",
    "  news_title_sentiment = news_spanish['news_title'].apply(lambda title: analyzer.predict(title).probas)\n",
    "  news_subtitle_sentiment = news_spanish['news_subtitle'].apply(lambda subtitle: analyzer.predict(subtitle).probas)\n",
    "  news_content_sentiment = news_spanish['news_text_content'].apply(lambda content: analyzer.predict(content).probas)\n",
    "\n",
    "  news_spanish['news_title_prob_POS_pysent'] = news_title_sentiment.apply(lambda sentiment: sentiment['POS'])\n",
    "  news_spanish['news_title_prob_NEU_pysent'] = news_title_sentiment.apply(lambda sentiment: sentiment['NEU'])\n",
    "  news_spanish['news_title_prob_NEG_pysent'] = news_title_sentiment.apply(lambda sentiment: sentiment['NEG'])\n",
    "\n",
    "  news_spanish['news_subtitle_prob_POS_pysent'] = news_subtitle_sentiment.apply(lambda sentiment: sentiment['POS'])\n",
    "  news_spanish['news_subtitle_prob_NEU_pysent'] = news_subtitle_sentiment.apply(lambda sentiment: sentiment['NEU'])\n",
    "  news_spanish['news_subtitle_prob_NEG_pysent'] = news_subtitle_sentiment.apply(lambda sentiment: sentiment['NEG'])\n",
    "\n",
    "  news_spanish['news_text_content_prob_POS_pysent'] = news_content_sentiment.apply(lambda sentiment: sentiment['POS'])\n",
    "  news_spanish['news_text_content_prob_NEU_pysent'] = news_content_sentiment.apply(lambda sentiment: sentiment['NEU'])\n",
    "  news_spanish['news_text_content_prob_NEG_pysent'] = news_content_sentiment.apply(lambda sentiment: sentiment['NEG'])\n",
    "\n",
    "  news_spanish['news_title_sent_sentspanish'] = news_spanish['news_title'].apply(lambda title: sentiment.sentiment(title))\n",
    "  news_spanish['news_subtitle_sent_sentspanish'] = news_spanish['news_subtitle'].apply(lambda subtitle: sentiment.sentiment(subtitle))\n",
    "  news_spanish['news_text_content_sent_sentspanish'] = news_spanish['news_text_content'].apply(lambda content: sentiment.sentiment(content))\n",
    "\n",
    "  news_spanish.to_csv(f'news_sentiment_spanish/news_sentiment_spanish-{current_year}.csv', index = False)\n",
    "  \n",
    "  print(f'CALCULO DE SENTIMIENTO (ESPAÑOL) DE NOTICIAS DEL AÑO {current_year} REALIZADO EXITOSAMENTE')\n",
    "\n",
    "print('*' * 80)\n",
    "print('CALCULO DE SENTIMIENTO (ESPAÑOL) REALIZADO EXITOSAMENTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6.1 (OPCIONAL): Persistencia de las noticias en español con sentimiento (destino: local)\n",
    "Las noticias serán guardadas en el mismo directorio de este notebook como **ALL_NEWS_SENTIMENT.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_local('news_sentiment_spanish', 'ALL_NEWS_SENTIMENT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6.2 (OPCIONAL): Persistencia de las noticias en español con sentimiento (destino: nube)\n",
    "En caso de querer subir información a la nube se debe utilizar el método **upload_to_lz()**, en donde *database* es el nombre de la base de datos a la cual usted esté autorizado y *table_name* el nombre con el que la tabla quedará cargada en la nube. Tenga en cuenta que en el mismo directorio de este notebook debe existir un archivo llamado **credentials.json**, debe contener lo siguiente: **{ \"user\": \"su_usuario\", \"password\": \"su_contraseña\", \"server\": \"sbmdeblze004\" }**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_local('news_sentiment_spanish', 'ALL_NEWS_SENTIMENT')\n",
    "all_news = pd.read_csv('ALL_NEWS_SENTIMENT.csv')\n",
    "all_news = all_news.astype(str)\n",
    "\n",
    "database = 'proceso'\n",
    "table_name = 'dasolano_portafolio_news_sentiment'\n",
    "\n",
    "upload_to_lz(dataframe = all_news, database = database, table_name = table_name)\n",
    "clear_output(wait = True)\n",
    "!del ALL_NEWS_SENTIMENT.csv\n",
    "print(f'LAS NOTICIAS HAN SIDO CARGADAS A LA NUBE EXITOSAMENTE. UBICACIÓN LZ: {database}.{table_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 7: Cálculo del sentimiento en español (título, subtítulo y contenido unidos)\n",
    "\n",
    "Se calcula el sentimiento de la unión (concatenación) del título, subtitulo y contenido de cada noticia usando las librerías [pysentimiento](https://github.com/pysentimiento/pysentimiento)\n",
    "y [sentiment-spanish](https://github.com/sentiment-analysis-spanish/sentiment-spanish). El resultado se guardará en un archivo (en el mismo directorio de este notebook) llamado **news_sentiment_spanish_joined.csv**. Para ello, ejecute la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('news_sentiment_spanish_joined'):\n",
    "  if os.listdir('news_sentiment_spanish_joined'):\n",
    "    !rmdir /s /q news_sentiment_spanish_joined\n",
    "    !mkdir news_sentiment_spanish_joined\n",
    "else:\n",
    "  !mkdir news_sentiment_spanish_joined\n",
    "  \n",
    "for current_year in range(int(start_year), int(end_year) + 1):\n",
    "\n",
    "  news_spanish = pd.read_csv(f'news/news-{current_year}.csv')\n",
    "  news_spanish = news_spanish.astype(str)\n",
    "\n",
    "  news_spanish['news_joined'] = news_spanish['news_title'] + '. ' + news_spanish['news_subtitle'] + '. ' + news_spanish['news_text_content']\n",
    "\n",
    "  del news_spanish['news_title']\n",
    "  del news_spanish['news_subtitle']\n",
    "  del news_spanish['news_text_content']\n",
    "\n",
    "  news_spanish_joined = news_spanish['news_joined'].apply(lambda news: analyzer.predict(news).probas)\n",
    "\n",
    "  news_spanish['news_joined_prob_POS_pysent'] = news_spanish_joined.apply(lambda sentiment: sentiment['POS'])\n",
    "  news_spanish['news_joined_prob_NEU_pysent'] = news_spanish_joined.apply(lambda sentiment: sentiment['NEU'])\n",
    "  news_spanish['news_joined_prob_NEG_pysent'] = news_spanish_joined.apply(lambda sentiment: sentiment['NEG'])\n",
    "\n",
    "  news_spanish['news_joined_sent_sentspanish'] = news_spanish['news_joined'].apply(lambda joined_text: sentiment.sentiment(joined_text))\n",
    "\n",
    "  news_spanish.to_csv(f'news_sentiment_spanish_joined/news_sentiment_spanish_joined-{current_year}.csv', index = False)\n",
    "\n",
    "  print(f'CALCULO DE SENTIMIENTO (ESPAÑOL) DE NOTICIAS DEL AÑO {current_year} REALIZADO EXITOSAMENTE')\n",
    "\n",
    "print('*' * 80)\n",
    "print('CALCULO DE SENTIMIENTO (ESPAÑOL) REALIZADO EXITOSAMENTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 7.1 (OPCIONAL): Persistencia de las noticias en español con sentimiento titulo + subtitulo + contenido (destino: local)\n",
    "Las noticias serán guardadas en el mismo directorio de este notebook como **ALL_NEWS_SENTIMENT_JOINED.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_local('news_sentiment_spanish_joined', 'ALL_NEWS_SENTIMENT_JOINED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 7.2 (OPCIONAL): Persistencia de las noticias en español con sentimiento titulo + subtitulo + contenido (destino: nube)\n",
    "En caso de querer subir información a la nube se debe utilizar el método **upload_to_lz()**, en donde *database* es el nombre de la base de datos a la cual usted esté autorizado y *table_name* el nombre con el que la tabla quedará cargada en la nube. Tenga en cuenta que en el mismo directorio de este notebook debe existir un archivo llamado **credentials.json**, debe contener lo siguiente: **{ \"user\": \"su_usuario\", \"password\": \"su_contraseña\", \"server\": \"sbmdeblze004\" }**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_local('news_sentiment_spanish_joined', 'ALL_NEWS_SENTIMENT_JOINED')\n",
    "all_news = pd.read_csv('ALL_NEWS_SENTIMENT_JOINED.csv')\n",
    "all_news = all_news.astype(str)\n",
    "\n",
    "database = 'proceso'\n",
    "table_name = 'dasolano_portafolio_news_sentiment_joined'\n",
    "\n",
    "upload_to_lz(dataframe = all_news, database = database, table_name = table_name)\n",
    "clear_output(wait = True)\n",
    "!del ALL_NEWS_SENTIMENT_JOINED.csv\n",
    "print(f'LAS NOTICIAS HAN SIDO CARGADAS A LA NUBE EXITOSAMENTE. UBICACIÓN LZ: {database}.{table_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 8: Traducción a inglés de las noticias\n",
    "\n",
    "Traducción a inglés de las noticias usando la librería [deep-translator](https://github.com/nidhaloff/deep-translator). El resultado se guardará en un archivo (en el mismo directorio de este notebook) llamado **search_results_cleaned_english.csv**. Para ello, ejecute la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('news_english'):\n",
    "  if os.listdir('news_english'):\n",
    "    !rmdir /s /q news_english\n",
    "    !mkdir news_english\n",
    "else:\n",
    "  !mkdir news_english\n",
    "\n",
    "for current_year in range(int(start_year), int(end_year) + 1):\n",
    "  news_spanish = pd.read_csv(f'news/news-{current_year}.csv')\n",
    "  news_spanish = news_spanish.astype(str)\n",
    "\n",
    "  news_location = f'news_english/news_english-{current_year}'\n",
    "\n",
    "  news_english = translate_news(news_spanish, news_location)\n",
    "  news_english.to_csv(f'{news_location}.csv', index = False)\n",
    "  shutil.rmtree(news_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 8.1 (OPCIONAL): Persistencia de las noticias (destino: local)\n",
    "Las noticias serán guardadas en el mismo directorio de este notebook como **ALL_NEWS_ENGLISH.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_local('news_english', 'ALL_NEWS_ENGLISH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 8.2 (OPCIONAL): Persistencia de las noticias (destino: nube)\n",
    "En caso de querer subir información a la nube se debe utilizar el método **upload_to_lz()**, en donde *database* es el nombre de la base de datos a la cual usted esté autorizado y *table_name* el nombre con el que la tabla quedará cargada en la nube. Tenga en cuenta que en el mismo directorio de este notebook debe existir un archivo llamado **credentials.json**, debe contener lo siguiente: **{ \"user\": \"su_usuario\", \"password\": \"su_contraseña\", \"server\": \"sbmdeblze004\" }**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_local('news_english', 'ALL_NEWS_ENGLISH')\n",
    "all_news = pd.read_csv('ALL_NEWS_ENGLISH.csv')\n",
    "all_news = all_news.astype(str)\n",
    "\n",
    "database = 'proceso'\n",
    "table_name = 'dasolano_portafolio_news_english'\n",
    "\n",
    "upload_to_lz(dataframe = all_news, database = database, table_name = table_name)\n",
    "clear_output(wait = True)\n",
    "!del ALL_NEWS_ENGLISH.csv\n",
    "print(f'LAS NOTICIAS HAN SIDO CARGADAS A LA NUBE EXITOSAMENTE. UBICACIÓN LZ: {database}.{table_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 9: Cálculo del sentimiento en inglés (título, subtítulo y contenido)\n",
    "\n",
    "Se calcula el sentimiento del título, subtitulo y contenido de cada noticia usando las librerías [NLTK](https://www.nltk.org/), [TextBlob](https://textblob.readthedocs.io/en/dev/) y [FinBert](https://huggingface.co/yiyanghkust/finbert-tone). El resultado se guardará en un archivo (en el mismo directorio de este notebook) llamado **news_sentiment_english.csv**. Para ello, ejecute la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('news_sentiment_english'):\n",
    "  if os.listdir('news_sentiment_english'):\n",
    "    !rmdir /s /q news_sentiment_english\n",
    "    !mkdir news_sentiment_english\n",
    "else:\n",
    "  !mkdir news_sentiment_english\n",
    "\n",
    "for current_year in range(int(start_year), int(end_year) + 1):\n",
    "    news_english = pd.read_csv(f'news_english/news_english-{current_year}.csv')\n",
    "    news_english = news_english.astype(str)\n",
    "\n",
    "    #NLTK\n",
    "\n",
    "    news_english_title_nltk = news_english['news_title_english'].apply(lambda title: sia.polarity_scores(str(title)))\n",
    "    news_english_subtitle_nltk = news_english['news_subtitle_english'].apply(lambda subtitle: sia.polarity_scores(str(subtitle)))\n",
    "    news_english_content_nltk = news_english['news_text_content_english'].apply(lambda content: sia.polarity_scores(str(content)))\n",
    "\n",
    "    news_english['news_title_english_polarity_POS_nltk'] = news_english_title_nltk.apply(lambda sentiment: sentiment['pos'])\n",
    "    news_english['news_title_english_polarity_NEU_nltk'] = news_english_title_nltk.apply(lambda sentiment: sentiment['neu'])\n",
    "    news_english['news_title_english_polarity_NEG_nltk'] = news_english_title_nltk.apply(lambda sentiment: sentiment['neg'])\n",
    "    news_english['news_title_english_polarity_COM_nltk'] = news_english_title_nltk.apply(lambda sentiment: sentiment['compound'])\n",
    "\n",
    "    news_english['news_subtitle_english_polarity_POS_nltk'] = news_english_subtitle_nltk.apply(lambda sentiment: sentiment['pos'])\n",
    "    news_english['news_subtitle_english_polarity_NEU_nltk'] = news_english_subtitle_nltk.apply(lambda sentiment: sentiment['neu'])\n",
    "    news_english['news_subtitle_english_polarity_NEG_nltk'] = news_english_subtitle_nltk.apply(lambda sentiment: sentiment['neg'])\n",
    "    news_english['news_subtitle_english_polarity_COM_nltk'] = news_english_subtitle_nltk.apply(lambda sentiment: sentiment['compound'])\n",
    "\n",
    "    news_english['news_text_content_english_polarity_POS_nltk'] = news_english_content_nltk.apply(lambda sentiment: sentiment['pos'])\n",
    "    news_english['news_text_content_english_polarity_NEU_nltk'] = news_english_content_nltk.apply(lambda sentiment: sentiment['neu'])\n",
    "    news_english['news_text_content_english_polarity_NEG_nltk'] = news_english_content_nltk.apply(lambda sentiment: sentiment['neg'])\n",
    "    news_english['news_text_content_english_polarity_COM_nltk'] = news_english_content_nltk.apply(lambda sentiment: sentiment['compound'])\n",
    "\n",
    "    #TEXTBLOB\n",
    "\n",
    "    news_english_title_textblob = news_english['news_title_english'].apply(lambda title: TextBlob(str(title)).sentiment)\n",
    "    news_english_subtitle_textblob = news_english['news_subtitle_english'].apply(lambda subtitle: TextBlob(str(subtitle)).sentiment)\n",
    "    news_english_content_textblob = news_english['news_text_content_english'].apply(lambda content: TextBlob(str(content)).sentiment)\n",
    "\n",
    "    news_english['news_title_english_pol_textblob'] = news_english_title_textblob.apply(lambda sentiment: sentiment.polarity)\n",
    "    news_english['news_title_english_sub_textblob'] = news_english_title_textblob.apply(lambda sentiment: sentiment.subjectivity)\n",
    "\n",
    "    news_english['news_subtitle_english_pol_textblob'] = news_english_subtitle_textblob.apply(lambda sentiment: sentiment.polarity)\n",
    "    news_english['news_subtitle_english_sub_textblob'] = news_english_subtitle_textblob.apply(lambda sentiment: sentiment.subjectivity)\n",
    "\n",
    "    news_english['news_text_content_english_pol_textblob'] = news_english_content_textblob.apply(lambda sentiment: sentiment.polarity)\n",
    "    news_english['news_text_content_english_sub_textblob'] = news_english_content_textblob.apply(lambda sentiment: sentiment.subjectivity)\n",
    "\n",
    "    #FINBERT\n",
    "\n",
    "    news_english_title_textblob = news_english['news_title_english'].apply(lambda title: nlp(str(title)))\n",
    "    news_english_subtitle_textblob = news_english['news_subtitle_english'].apply(lambda subtitle: nlp(str(subtitle)))\n",
    "\n",
    "    news_english['news_title_english_label_finbert'] = news_english_title_textblob.apply(lambda sentiment: sentiment[0]['label'])\n",
    "    news_english['news_title_english_label_score_finbert'] = news_english_title_textblob.apply(lambda sentiment: sentiment[0]['score'])\n",
    "\n",
    "    news_english['news_subtitle_english_label_finbert'] = news_english_subtitle_textblob.apply(lambda sentiment: sentiment[0]['label'])\n",
    "    news_english['news_subtitle_english_label_score_finbert'] = news_english_subtitle_textblob.apply(lambda sentiment: sentiment[0]['score'])\n",
    "\n",
    "    news_english.to_csv(f'./news_sentiment_english/news_sentiment_english-{current_year}.csv', index = False)\n",
    "\n",
    "    print(f'CALCULO DE SENTIMIENTO (INGLÉS) DE NOTICIAS DEL AÑO {current_year} REALIZADO EXITOSAMENTE')\n",
    "\n",
    "print('*' * 80)\n",
    "print('CALCULO DE SENTIMIENTO (INGLÉS) REALIZADO EXITOSAMENTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 9.1 (OPCIONAL): Persistencia de las noticias en inglés con sentimiento (destino: local)\n",
    "Las noticias serán guardadas en el mismo directorio de este notebook como **ALL_NEWS_SENTIMENT_ENGLISH.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_local('news_sentiment_english', 'ALL_NEWS_SENTIMENT_ENGLISH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 9.2 (OPCIONAL): Persistencia de las noticias en inglés con sentimiento (destino: nube)\n",
    "En caso de querer subir información a la nube se debe utilizar el método **upload_to_lz()**, en donde *database* es el nombre de la base de datos a la cual usted esté autorizado y *table_name* el nombre con el que la tabla quedará cargada en la nube. Tenga en cuenta que en el mismo directorio de este notebook debe existir un archivo llamado **credentials.json**, debe contener lo siguiente: **{ \"user\": \"su_usuario\", \"password\": \"su_contraseña\", \"server\": \"sbmdeblze004\" }**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_local('news_sentiment_english', 'ALL_NEWS_SENTIMENT_ENGLISH')\n",
    "all_news = pd.read_csv('ALL_NEWS_SENTIMENT_ENGLISH.csv')\n",
    "all_news = all_news.astype(str)\n",
    "\n",
    "database = 'proceso'\n",
    "table_name = 'dasolano_portafolio_news_sentiment_english'\n",
    "\n",
    "upload_to_lz(dataframe = all_news, database = database, table_name = table_name)\n",
    "clear_output(wait = True)\n",
    "!del ALL_NEWS_SENTIMENT_ENGLISH.csv\n",
    "print(f'LAS NOTICIAS HAN SIDO CARGADAS A LA NUBE EXITOSAMENTE. UBICACIÓN LZ: {database}.{table_name}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
